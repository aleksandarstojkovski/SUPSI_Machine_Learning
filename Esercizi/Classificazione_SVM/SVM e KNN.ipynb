{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contenuti\n",
    "- [Scikit-learn](#Scikit-learn)\n",
    "- [Import delle librerie](#Import-delle-librerie)\n",
    "- [Dataset](#Dataset)\n",
    "- [Classificazione](#Classificazione)\n",
    "    - [k-NN e SVM](#k-NN-e-SVM)\n",
    "- [Cross-Validation](#Cross-Validation)\n",
    "- [Grid Search e Cross-Validation](#Grid-Search-e-Cross-Validation)\n",
    "- [Ottimizzazione iperparametri](#Ottimizzazione-iperparametri)\n",
    "- [Test](#Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esercitazione 3\n",
    "Nell'esercitazione odierna si vedrà come applicare gli algoritmi *k-NN* e *SVM* a un problema di classificazione multiclasse. A tal fine verrà utilizzata la libreria **Scikit-learn**, di cui sarà descritta l'API per l'addestramento e uso di classificatori. Nel corso dell'esercitazione si dovranno individuare le combinazioni di iperparametri che permettono di massimizzare l’accuratezza dei due classificatori sui dataset forniti tramite *Cross-Validation* e *Grid Search*.\n",
    "\n",
    "Infine si dovrà verificare l'accuratezza della soluzione trovata sul dataset di test per provarne l’effettiva capacità di generalizzazione.\n",
    "\n",
    "# Scikit-learn\n",
    "Scikit-learn è una libreria open source per Python che mette a disposizione numerose classi e funzionalità specifiche per il Machine Learning. Oltre a rendere disponibili i più comuni algoritmi per la classificazione, regressione e clustering, sono presenti anche diverse funzionalità per la manipolazione dei dati.\n",
    "\n",
    "La popolarità di Scikit-learn è dovuta principalmente alla sua facilità d'uso, all'integrazione con la libreria Numpy e alla possibilità di parametrizzare le operazioni messe a disposizione, pur mantenendo una API semplice.\n",
    "\n",
    "Per una lista completa delle funzionalità si rimanda alla [documentazione ufficiale](http://scikit-learn.org/stable/documentation.html).\n",
    "\n",
    "# Import delle librerie\n",
    "Per prima cosa è necessario eseguire l'import delle librerie utilizzate durante l'esecitazione. Il package della libreria Scikit-learn è denominato **sklearn**. Dal package è possibile caricare solamente i moduli necessari."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moduli di scikit-learn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, ParameterGrid, train_test_split\n",
    "\n",
    "import ml_utilities\n",
    "import ml_visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# Dataset\n",
    "Il dataset messo a disposizione consiste in un insieme di cifre (0-9) scritte a mano.\n",
    "<img src=\"dataset_resample.png\" alt=\"Processing training set\" style=\"width: 600px;\"/>\n",
    "\n",
    "I dataset di training \"pendigits_tr.txt\" e \"pendigits_tr_Pca_K2.txt\" contengono entrambi 7330 pattern etichettati (cifre da 0 a 9). Il primo contiene pattern 16-dimensionali (le coordinate x,y di otto punti equispaziati dopo normalizzazione e *resampling*) mentre il secondo consiste in una versione bidimensionale ottenuta tramite riduzione della dimensionalità (mediante l'algoritmo *Principal Component Analysis*), utile per eseguire test iniziali visualizzando pattern e risultati.\n",
    "\n",
    "Di seguito è fornita la procedura per il caricamento del dataset. È necessario assegnare alla variabile *dataset_path* il percorso dove sono memorizzati i due file. Tramite la variabile *feature_count* è possibile dichiarare quale delle due versioni del dataset si intende utilizzare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Scelta del dataset da utilizzare (16 o 2 features)\n",
    "feature_count = 2\n",
    "dataset_path = 'pendigits_tr_Pca_K2.txt'  # Impostare il percorso corretto\n",
    "\n",
    "# Caricamento del dataset\n",
    "dataset_patterns, dataset_labels = ml_utilities.load_labeled_dataset_from_txt(dataset_path, feature_count)\n",
    "print('Shape dataset:', dataset_patterns.shape)\n",
    "print('Shape labels:', dataset_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "Il dataset caricato può essere suddiviso in due parti: training e validation set. Attraverso il validation set sarà possibile valutare i risultati del classificatore addestrato sul training set al fine di individuare il valore ottimale per gli iperparametri.\n",
    "\n",
    "Visto che in Machine Learning è comune eseguire tale operazione, la libreria Scikit-learn mette a disposizione una apposita funzione, [**train_test_split(...)**](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html), che permette di separare un dataset in due parti. \n",
    "\n",
    "Il parametro *test_size* descrive la percentuale di pattern che dovrà essere contenuta nella seconda parte. Come configurazione predefinita **train_test_split(...)** mescola i pattern al fine di evitare che i dataset restituiti contengano pattern appartenenti solamente a un sottoinsieme delle classi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, validation_x, train_y, validation_y = train_test_split(dataset_patterns, dataset_labels, test_size=0.40)\n",
    "print('Shape training set:', train_x.shape)\n",
    "print('Shape validation set:', validation_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# Classificazione\n",
    "Di seguito vengono descritte le operazioni necessarie per creare e addestrare un classificatore. Uno dei punti di forza della libreria Scikit-learn è la sua facilità d'uso e l'uniformità delle chiamate alla libreria: si noti come queste operazioni necessitino solamente di due linee di codice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creazione di un classificatore\n",
    "dummy_clf = DummyClassifier(strategy='most_frequent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "Nell'esempio, il classificatore creato è un **DummyClassifier** la cui strategia è quella di assegnare ad ogni pattern la classe più numerosa nel training set.\n",
    "\n",
    "Il classificatore (*estimator* nel lessico di Scikit-learn) può essere addestrato tramite il metodo **.fit(...)** che prende in input un insieme di pattern etichettati X,y. I pattern (X) sono memorizzati per righe in un Numpy array bidimensionale mentre le etichette (y) in un Numpy array monodimensionale.\n",
    "\n",
    "N.B.: la notazione X (maiuscolo) e y (minuscolo) è normalmente utilizzata in Scikit-learn per indicare un set di pattern (X) e le rispettive etichette (y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addestramento\n",
    "dummy_clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "Una volta addestrato, un classificatore può essere utilizzato per riconoscere la classe di uno o più pattern. Per fare ciò, si può utilizzare il metodo **.predict(...)** passando come parametro una lista di pattern. Il risultato che si ottiene è una lista delle label predette dal classificatore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uso della funzione .predict(...)\n",
    "print('Classi predette:', dummy_clf.predict(validation_x[0:5]))\n",
    "print('Classi reali:', validation_y[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "In Scikit-learn è possibile misurare l'accuratezza di un classificatore su un determinato dataset richiamando il metodo **.score(...)** che prende in input un insieme di pattern etichettati X,y. Internamente il metodo classifica ogni singolo pattern di X e verifica se l'etichetta assegnata corrisponde alla corrispondente *entry* in y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uso della funzione .score(...)\n",
    "print('Accuratezza sul training set: {}'.format(dummy_clf.score(train_x, train_y)))\n",
    "print('Accuratezza sul validation set: {}'.format(dummy_clf.score(validation_x, validation_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "homework": true
   },
   "source": [
    "Si implementi la funzione **compute_accuracy(...)** in grado di calcolare l'accuratezza di un classificatore su un insieme di pattern etichettati X,y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "homework": true
   },
   "outputs": [],
   "source": [
    "# Esercizio di approfondimento: stima dell'accuratezza\n",
    "def compute_accuracy(classifier, X, y):\n",
    "    results = classifier.predict(X)\n",
    "    return (results == y).sum() / len(X)\n",
    "\n",
    "print('Accuratezza sul training set: {}'.format(compute_accuracy(dummy_clf, train_x, train_y)))\n",
    "print('Accuratezza sul validation set: {}'.format(compute_accuracy(dummy_clf, validation_x, validation_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "Per dati bidimensionali può essere utile visualizzare graficamente i pattern e la superfice decisionale del classificatore. Per fare ciò si può utilizzare la funzione **show_2D_results(...)** presente nel modulo ml_visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Uso di show_results\n",
    "ml_visualization.show_2D_results(dummy_clf, (train_x, train_y, 'Training'), (validation_x, validation_y, 'Validation'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## k-NN e SVM\n",
    "Abbiamo visto come, con Scikit-learn, sia possibile creare, addestrare e utilizzare un generico classificatore. Scikit-learn mette a disposizione una serie di classificatori tra cui [k-NN](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) e [SVM](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) che utilizzeremo per riconoscere i pattern caricati in precedenza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esercizio 1: creare ed addestrare un classificatore\n",
    "\n",
    "# In questo esercizio si richiede di creare 3 tipi di classificatore ...\n",
    "# - k-NN\n",
    "# - SVM con kernel lineare\n",
    "# - SVM con kernel rbf\n",
    "# A tal fine si chiede di prendere confidenza con la documentazione \n",
    "# identificando in essa gli iperparametri rilevanti per i diversi\n",
    "# classificatori / kernel.\n",
    "\n",
    "# Creazione del classificatore: soluzione\n",
    "# Di seguito è riportata la procedura corretta per creare i suddetti classificatori.\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "# clf = SVC(kernel=\"linear\", C=1)\n",
    "# clf = SVC(kernel=\"rbf\", C=1, gamma=0.1)\n",
    "\n",
    "# Addestramento del classificatore: soluzione\n",
    "clf.fit(train_x, train_y)\n",
    "\n",
    "# Calcolo accuratezza\n",
    "print('Accuratezza sul training set: {}'.format(clf.score(train_x, train_y)))\n",
    "print('Accuratezza sul validation set: {}'.format(clf.score(validation_x, validation_y)))\n",
    "\n",
    "#Visualizzazione 2D\n",
    "ml_visualization.show_2D_results(clf, (train_x, train_y, 'Training'), (validation_x, validation_y, 'Validation'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# Cross-Validation\n",
    "Se non si vuole riservare un sottoinsieme disgiunto per il validation set e sfruttare tutti i dati disponibili per training e validazione, si può utilizzare la tecnica *Cross-Validation* vista a lezione.  \n",
    "\n",
    "Si completi il codice nella cella seguente richiamando la funzione [**cross_val_score(...)**](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) di Scikit-learn che stima l'accuratezza di un classificatore (*estimator*) tramite *Cross-Validation* (con un numero di *fold* pari a *cv*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esercizio 2: eseguire la Cross Validation utilizzando la funzione cross_val_score\n",
    "# Reminder: la variabile dataset_patterns include già training e validation set\n",
    "\n",
    "cv_score = cross_val_score(KNeighborsClassifier(n_neighbors=5),\n",
    "                           dataset_patterns,\n",
    "                           dataset_labels,\n",
    "                           cv=4)\n",
    "print('Risultati CrossValidation:\\n', cv_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# Grid Search e Cross-Validation\n",
    "Dato un algoritmo, la ricerca degli iperparametri ottimi può essere automatizzata utilizzando, come visto a lezione, la classe [**GridSearchCV**](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) messa a disposizione da Scikit-learn.\n",
    "\n",
    "Questo metodo è particolarmente indicato nei casi in cui l'addestramento di un classificatore non richieda un tempo particolarmente lungo. Si consideri infatti che vengono creati e addestrati $(\\textit{# combinazioni degli iperparametri} \\times \\textit{# fold}) + 1$ classificatori."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creazione di un classificatore di tipo SVM\n",
    "clf = SVC()\n",
    "\n",
    "# Creazione della griglia di iperparametri\n",
    "param_grid = [{'kernel': ['rbf'], 'C': [1,10], 'gamma': [0.05,0.025]}]\n",
    "\n",
    "# Numero di fold per la Cross-validation\n",
    "n_folds = 3\n",
    "\n",
    "# Creazione di un oggetto di tipo GridSearchCV\n",
    "grid_search_cv = GridSearchCV(clf, param_grid, cv=n_folds)\n",
    "\n",
    "# Esecuzione della ricerca degli iperparametri \n",
    "grid_search_cv.fit(train_x, train_y)\n",
    "\n",
    "# Stampa risultati\n",
    "print('Combinazioni di parametri:\\n', grid_search_cv.cv_results_['params'])\n",
    "print('Accuratezza media per combinazione:\\n', grid_search_cv.cv_results_['mean_test_score'])\n",
    "print('Combinazione migliore:\\n', grid_search_cv.best_params_)\n",
    "print('Accuratezza media della combinazione migliore: {}'.format(grid_search_cv.best_score_))\n",
    "\n",
    "# Visualizzazione 2D\n",
    "ml_visualization.show_2D_results(grid_search_cv.best_estimator_,\n",
    "                                 (dataset_patterns, dataset_labels, 'Data'),\n",
    "                                 figsize=(9,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "Se si vuole testare esternamente al GridSearchCV(...) i migliori iperparametri precedentemente individuati (best_params_), si consiglia di verificarne la bontà utilizzando la funzione cross_val_score(...) che restituisce l'accuratezza per le singole fold. Viceversa, utilizzando l'intero training set sia per l'addestramento che per la valutazione si rischia di ottenere un valore di accuratezza non realistico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Costruisce un classificatore con i parametri trovati\n",
    "clf = SVC(**grid_search_cv.best_params_)\n",
    "print('Classificatore con parametri ottimali:\\n', clf, '\\n')\n",
    "\n",
    "# Cross validation\n",
    "cv_score = cross_val_score(clf, train_x, train_y, cv=n_folds)\n",
    "print('Accuracy di cross validation: ', cv_score)\n",
    "print('Accuracy media di cross validation: ', cv_score.mean())\n",
    "\n",
    "# Addestramento su tutto il dataset\n",
    "clf = SVC(**grid_search_cv.best_params_)\n",
    "clf.fit(train_x, train_y)\n",
    "print('Accuracy classificatore addestrato su tutto il training set:', clf.score(train_x, train_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# Ottimizzazione iperparametri\n",
    "Si individui il classificatore (*k-NN* o *SVM*) e la rispettiva combinazione di iperparametri che permettono di massimizzare l'accuratezza sul dataset fornito (16-dimensionale).\n",
    "\n",
    "Si consiglia di procedere eseguendo **GridSearchCV** su un insieme limitato di combinazioni raffinando la ricerca degli iperparametri in iterazioni successive. In questa maniera sarà possibile ridurre i tempi di attesa.\n",
    "\n",
    "Nella cella seguente è riportata la procedura per il caricamento del dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caricamento del dataset\n",
    "feature_count = 16\n",
    "dataset_path = 'pendigits_tr.txt'  # Impostare il percorso corretto\n",
    "\n",
    "dataset_patterns, dataset_labels = ml_utilities.load_labeled_dataset_from_txt(dataset_path, feature_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "Utilizzando il dataset appena caricato si identifichi una combinazione di iperparametri ottimi. A tal fine nella cella seguente è possibile sperimentare le tecniche viste in questa esercitazione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esercizio 3: ottimizzazione iperparametri\n",
    "\n",
    "# La strategia migliore è quella di utilizzare GridSearchCV sull'intero dataset\n",
    "# tentando diverse combinazioni di iperparametri un po' per volta (4-8 per volta)\n",
    "# in maniera tale da poter ottenere velocemente i risultati.\n",
    "\n",
    "# Per ottenere punteggi attendibili è necessario utilizzare un numero\n",
    "# di cv (fold) compreso tra 3 e 10\n",
    "\n",
    "# Creazione del classificatore e della griglia di iperparametri\n",
    "clf = KNeighborsClassifier()\n",
    "param_grid = [{'n_neighbors': range(1, 11)}]\n",
    "\n",
    "#clf = SVC()\n",
    "#param_grid = [{'kernel': ['linear'], 'C': [1, 5, 10]}]\n",
    "\n",
    "#clf = SVC()\n",
    "#param_grid = [{'kernel': ['rbf'], 'C': [1, 10], 'gamma': [0.1, 0.01]}]\n",
    "\n",
    "# Numero di fold per la Cross-validation\n",
    "n_folds = 3\n",
    "\n",
    "# Creazione di un oggetto di tipo GridSearchCV\n",
    "experiment_gscv = GridSearchCV(clf, param_grid, cv=n_folds)\n",
    "\n",
    "# Esecuzione della ricerca degli iperparametri \n",
    "experiment_gscv.fit(dataset_patterns, dataset_labels)\n",
    "\n",
    "# Stampa risultati\n",
    "print('Combinazioni di parametri:\\n', experiment_gscv.cv_results_['params'])\n",
    "print('Accuratezza media per combinazione:\\n', experiment_gscv.cv_results_['mean_test_score'])\n",
    "print('Combinazione migliore:\\n', experiment_gscv.best_params_)\n",
    "print('Accuratezza media della combinazione migliore: {}'.format(experiment_gscv.best_score_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
